; .............................................................................
; LmServer
; .............................................................................
[LmServer - environment]
PUBLIC_USER: kubi
PUBLIC_FQDN: @PUBLIC_FQDN@
OGC_SERVICE_URL: http://@PUBLIC_FQDN@/ogc
WEBSERVICES_ROOT: http://@PUBLIC_FQDN@

SMTP_SERVER: @SMTPSERVER@
SMTP_SENDER: no-reply-lifemapper@@PUBLIC_FQDN@

APP_PATH: @LMHOME@
TEMP_PATH: @TEMPDIR@
DATA_PATH: @DATADIR_SERVER@
SCRATCH_PATH: @LMSCRATCHDISK@

;; These 2 variables are identical in config.lmcompute.ini
PID_PATH: @LMSCRATCHDISK@/run
SHARED_DATA_PATH: @DATADIR_SHARED@

; .............................................................................
[LmServer - registeredcompute]
COMPUTE_NAME: 
COMPUTE_IP: 
COMPUTE_IP_MASK: 
COMPUTE_CONTACT_USERID:
COMPUTE_CONTACT_EMAIL:
COMPUTE_CONTACT_FIRSTNAME:
COMPUTE_CONTACT_LASTNAME:
COMPUTE_INSTITUTION:
COMPUTE_ADDR1:
COMPUTE_ADDR2: 
COMPUTE_ADDR3: 

; .............................................................................
[LmServer - pipeline]
ARCHIVE_USER: kubi
TROUBLESHOOTERS: null@nowhere.com
 
; ...................
; SDM Params
; ...................
SPECIES_EXP_YEAR: 2016
SPECIES_EXP_MONTH: 8
SPECIES_EXP_DAY: 3
POINT_COUNT_MIN: 30
POINT_COUNT_MAX: 500
WORKER_JOB_LIMIT: 50
ALGORITHMS: BIOCLIM,ATT_MAXENT

; ...................
; Species data vals
; ...................
DATASOURCE: GBIF
;; Used when DATASOURCE is GBIF. 
GBIF_TAXONOMY_FILENAME: gbif_taxonomy.txt
GBIF_OCCURRENCE_FILENAME: gbif_subset.txt
GBIF_PROVIDER_FILENAME: gbif_orgs.txt

;; Used when DATASOURCE is BISON. 
BISON_TSN_FILENAME: bison_species_tsns.txt

;; Used when DATASOURCE is IDIGBIO 
IDIG_OCCURRENCE_DATA: idig_occurrences_localities
IDIG_OCCURRENCE_DATA_DELIMITER: ,

;; The default SPECIES_DATA set on 'lifemapper-server' roll installation
;; Used only when DATASOURCE is <> GBIF, IDIGBIO, or BISON. 
;; Change defaults in @LMHOME@/config/site.ini
USER_OCCURRENCE_DATA: @SPECIES_DATA@
USER_OCCURRENCE_DATA_DELIMITER: ,

; ...................
; Env Package Vals
; ...................
;; The default SCENARIO_PACKAGE (10min-past-present-future) is filled in and  
;; installed during 'lifemapper-server' roll installation matches these default 
;; scenarios. 
;; If LmServer and LmCompute are on the same server, SCENARIO_PACKAGE_SEED
;; in the [LmCompute - environment] section should match SCENARIO_PACKAGE here
SCENARIO_PACKAGE: @SCENARIO_PACKAGE@
;; These will be created from SCENARIO_PACKAGE and written to that config file
SCENARIO_PACKAGE_EPSG: @EPSG@
SCENARIO_PACKAGE_MAPUNITS: 
SCENARIO_PACKAGE_MODEL_SCENARIO: 
SCENARIO_PACKAGE_PROJECTION_SCENARIOS: 


; BISON values (Algs=ATT_MAXENT)
;; SCENARIO_PACKAGE: 30sec-present-future-CONUS

; PRAGMA values (Algs=BIOCLIM)
;; SCENARIO_PACKAGE: 30sec-present-future-SEA

; ...................
; Global PAM vals
; ...................
ASSEMBLE_PAMS: True
GRID_NAME: lmgrid_1d
GRID_CELLSIZE: 1
GRID_NUM_SIDES: 4

INTERSECT_FILTERSTRING: None
INTERSECT_VALNAME: pixel
INTERSECT_MINPERCENT: 25
INTERSECT_MINPRESENCE: 1
INTERSECT_MAXPRESENCE: 255

; .............................................................................
[LmServer - dbserver]
CONNECTION_PORT: 6432
DB_HOSTNAME: @DB_FQDN@

; .............................................................................
[LmServer - Matt Daemon]
; MattDaemon constants
MAX_MAKEFLOWS: 5

; Catalog Server constants
CS_PID_FILE: @LMSCRATCHDISK@/run/catalog_server.pid
CS_LOG_FILE: @LMSCRATCHDISK@/log/catalog_server.log
CS_PORT: 9097
CS_OPTIONS: -n @PUBLIC_FQDN@ -B %(CS_PID_FILE)s -p %(CS_PORT)s -m 100 -o %(CS_LOG_FILE)s -O 100M -H @LMSCRATCHDISK@/catalog.history 

;Use: ./catalog_server [options]
;where options are:
; -b,--background                Run as a daemon.
; -B,--pid-file=<file>           Write process identifier (PID) to file.
; -d,--debug=<subsystem>         Enable debugging for this subsystem
; -h,--help                      Show this help screen
; -H,--history=<directory>       Record catalog history to this directory.
; -I,--interface=<addr>          Listen only on this network interface.
; -l,--lifetime=<secs>           Lifetime of data, in seconds (default is 1800)
; -L,--update-log=<file>         Log new updates to this file.
; -m,--max-jobs=<n>              Maximum number of child processes.  (default is 50)
; -M,--server-size=<size>        Maximum size of a server to be believed.  (default is any)
; -n,--name=<name>               Preferred host name of this server.
; -o,--debug-file=<file>         Send debugging to this file. (can also be :stderr, :stdout, :syslog, or :journal)
; -O,--debug-rotate-max=<bytes>  Rotate debug file once it reaches this size. (default 10M, 0 disables)
; -p,--port=<port>               Port number to listen on (default is 9097)
; -S,--single                    Single process mode; do not work on queries.
; -T,--timeout=<time>            Maximum time to allow a query process to run.  (default is 60s)
; -u,--update-host=<host>        Send status updates to this host. (default is catalog.cse.nd.edu)
; -U,--update-interval=<time>    Send status updates at this interval. (default is 5m)
; -v,--version                   Show version string
; -Z,--port-file=<file>          Select port at random and write it to this file. (default: disabled)

; Worker Factory constants
WORKER_OPTIONS: -C @PUBLIC_FQDN@:%(CS_PORT)s -s @LMSCRATCHDISK@
; TODO: Evaluate if we want to use this directory, this is where the actually worker binary is put
WORKER_SHARED_DIR: @DATADIR_SHARED@
WF_OPTIONS: -M lifemapper.\\* -T sge -w 2 -W 5 -E "%(WORKER_OPTIONS)s" -S %(WORKER_SHARED_DIR)s
; To add debugging of job info, add something like '-B "-j y -o /home/lmwriter/jobLog.out"'

;Use: work_queue_factory [options]
;where options are:
; -M,--master-name=<project>     Project name of masters to serve, can be a regular expression.
; -F,--foremen-name=<project>    Foremen to serve, can be a regular expression.
; -T,--batch-type=<type>         Batch system type (required). One of: local, wq, condor, sge, torque, moab, slurm, chirp, amazon
; -P,--password                  Password file for workers to authenticate to master.
; -C,--config-file=<file>        Use configuration file <file>.
; -w,--min-workers               Minimum workers running.  (default=5)
; -W,--max-workers               Maximum workers running.  (default=100)
; --tasks-per-worker             Average tasks per worker. (default=one task per core)
; -t,--timeout=<time>            Workers abort after this amount of idle time. (default=300)
; -E,--extra-options=<options>   Extra options that should be added to the worker.
; --cores=<n>                    Set the number of cores requested per worker.
; --gpus=<n>                     Set the number of GPUs requested per worker.
; --memory=<mb>                  Set the amount of memory (in MB) requested per worker.
; --disk=<mb>                    Set the amount of disk (in MB) requested per worker.
; --autosize                     Automatically size a worker to an available slot (Condor only).
; --condor-requirements          Manually set requirements for the workers as condor jobs. May be specified several times, with the expresions and-ed together (Condor only).
; --factory-timeout              Exit after no master has been seen in <n> seconds.
; -S,--scratch-dir               Use this scratch dir for temporary files. (default is /tmp/wq-pool-$uid)
; -c,--capacity                  Use worker capacity reported by masters. 
; -d,--debug=<subsystem>         Enable debugging for this subsystem.
; --amazon-credentials           Specify path to Amazon credentials (for use with -T amazon)
; --amazon-ami                   Specify amazon machine image (AMI). (for use with -T amazon)
; -o,--debug-file=<file>         Send debugging to this file. (can also be :stderr, :stdout, :syslog, or :journal)
; -h,--help                      Show this screen.

; Makeflow constants
;** MAKEFLOW_BIN: @LMHOME@/bin/makeflow
MAKEFLOW_OPTIONS: -T wq -t 600 -u 600 -X @LMSCRATCHDISK@/worker/ -a -C @PUBLIC_FQDN@:%(CS_PORT)s 

;Use: /opt/lifemapper/bin/makeflow [options] <dagfile>
;Frequently used options:
;
; -c,--clean=<type>              Clean up: remove logfile and all targets. Optional specification [intermediates, outputs] removes only the indicated files.
; -T,--batch-type=<type>         Batch system type: (default is local)
;                                local, wq, condor, sge, torque, moab, slurm, chirp, amazon
;
;Other options are:
; -a,--advertise                 Advertise the master information to a catalog server.
; --amazon-credentials           Specify path to Amazon credentials (for use with -T amazon)
; --amazon-ami                   Specify amazon-ami (for use with -T amazon)
; -A,--disable-afs-check         Disable the check for AFS. (experts only.)
; -B,--batch-options=<options>   Add these options to all batch submit files.
; -C,--catalog-server=<catalog>  Set catalog server to <catalog>. Format: HOSTNAME:PORT 
; -d,--debug=<subsystem>         Enable debugging for this subsystem
; -f,--summary-log=<file>        Write summary of workflow to this file upon success or failure.
; -F,--wq-fast-abort=<#>         Work Queue fast abort multiplier.       (default is deactivated)
; -h,--help                      Show this help screen.
; -j,--max-local=<#>             Max number of local jobs to run at once.   (default is # of cores)
; -J,--max-remote=<#>            Max number of remote jobs to run at once.
;                                             (default 1000 for -Twq, 100 otherwise.)
; -l,--makeflow-log=<logfile>    Use this file for the makeflow log.      (default is X.makeflowlog)
; -L,--batch-log=<logfile>       Use this file for the batch system log.  (default is X.<type>log)
; -m,--email=<email>             Send summary of workflow to this email address upon success or failure.
; -N,--project-name=<project>    Set the project name to <project>
; -o,--debug-file=<file>         Send debugging to this file. (can also be :stderr, :stdout, :syslog, or :journal)
;    --debug-rotate-max=<bytes>  Rotate debug file once it reaches this size.
;    --password                  Password file for authenticating workers.
; -p,--port=<port>               Port number to use with Work Queue.     (default is 9123, 0=arbitrary)
; -P,--priority=<integer>        Priority. Higher the value, higher the priority.
; -R,--retry                     Automatically retry failed batch jobs up to 100 times.
; -r,--retry-count=<n>           Automatically retry failed batch jobs up to n times.
;    --wait-for-files-upto=<n>   Wait for output files to be created upto n seconds (e.g., to deal with NFS semantics).
; -S,--submission-timeout=<#>    Time to retry failed batch job submission.  (default is 3600s)
; -t,--wq-keepalive-timeout=<#>  Work Queue keepalive timeout.           (default is 30s)
; -u,--wq-keepalive-interval=<#> Work Queue keepalive interval.         (default is 120s)
; -v,--version                   Show version string
; -W,--wq-schedule=<mode>        Work Queue scheduling algorithm.        (time|files|fcfs)
;    --working-dir=<dir|url>     Working directory for the batch system.
;    --wrapper=<cmd>             Wrap all commands with this prefix.
;    --wrapper-input=<cmd>       Wrapper command requires this input file.
;    --wrapper-output=<cmd>      Wrapper command produces this output file.
; -X,--change-directory          Change directory: chdir to enable executing the Makefile in other directory.
; -z,--zero-length-error         Force failure on zero-length output files 
; -Z,--port-file=<file>          Select port at random and write it to this file.
;    --disable-wq-cache          Disable Work Queue caching.           (default is false)
;    --log-verbose               Add node id symbol tags in the makeflow log.     (default is false)
; --docker=<image>               Run each task with a container based on this docker image.
; --docker-tar=<tar file>        Load docker image from the tar file.
; --skip-file-check              Indicate user trusts inputs exist.
; --work-queue-preferred-connection Indicate preferred master connection. Choose one of by_ip or by_hostname. (default is by_ip)
;
;*Monitor Options:
;
; --monitor=<dir>                Enable the resource monitor, and write the monitor logs to <dir>.
;    --monitor-interval=<#>      Set monitor interval to <#> seconds.    (default is 1 second)
;    --monitor-with-time-series  Enable monitor time series.           (default is disabled)
;    --monitor-with-opened-files Enable monitoring of openened files.    (default is disabled)
;    --monitor-log-fmt=<fmt>     Format for monitor logs.             (default resource-rule-%%)

; .............................................................................
[LmClient - Open Tree of Life]
OTL_HINT_URL: http://api.opentreeoflife.org/v2/tnrs/autocomplete_name
OTL_TREE_WEB_URL: http://api.opentreeoflife.org/v2/tree_of_life/subtree

; .............................................................................
[LmClient - contact]
INSTITUTION_NAME: University of Kansas Biodiversity Institute
ADMIN_NAME: Aimee Stewart
ADMIN_EMAIL: aimee.stewart@ku.edu 

